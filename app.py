import streamlit as st
import numpy as np
import torch
import torch.nn.functional as F
import plotly.express as px
import pandas as pd

# ==========================================
# é¡µé¢é…ç½®
# ==========================================
st.set_page_config(
    page_title="Transformer & Mamba æ·±åº¦è§£æ",
    page_icon="ğŸ§¬",
    layout="wide",
    initial_sidebar_state="expanded",
)

st.title("ğŸ¤– Transformer vs ğŸ Mambaï¼šæ ¸å¿ƒæœºåˆ¶å¯è§†åŒ–")
st.markdown("""
> **"What I cannot create, I do not understand."** â€” Richard Feynman
>
> æœ¬é¡¹ç›®é€šè¿‡ **Manim åŠ¨ç”»** (å®è§‚åŸç†) ä¸ **äº¤äº’å¼æ¨å¯¼** (å¾®è§‚æ•°å€¼) çš„ç»“åˆï¼Œå¸¦ä½ æ˜¾å¾®é•œå¼è§‚å¯Ÿ Transformer ä¸ Mamba çš„å†…éƒ¨è¿ä½œã€‚
""")

# ==========================================
# å·¦ä¾§è¾¹æ ï¼šç»Ÿä¸€å‚æ•°æ§åˆ¶
# ==========================================
with st.sidebar:
    st.header("âš™ï¸ å®éªŒå®¤è®¾ç½®")
    
    st.subheader("1. Transformer å‚æ•°")
    d_model = st.slider("åµŒå…¥ç»´åº¦ (d_model)", 4, 16, 8, step=4, help="æ¯ä¸ª Token ç”¨å¤šå°‘ç»´å‘é‡è¡¨ç¤º")
    n_heads = st.radio("å¤šå¤´æ•°é‡ (Heads)", [1, 2, 4], help="å°†ç»´åº¦åˆ‡åˆ†ä¸ºå‡ ä¸ªå¤´å¹¶è¡Œè®¡ç®—")
    d_k = d_model // n_heads
    
    st.divider()
    
    st.subheader("2. Mamba å‚æ•°")
    d_state = st.slider("çŠ¶æ€ç»´åº¦ (d_state/N)", 2, 8, 4, help="SSM éšçŠ¶æ€æ°´ç®±çš„å¤§å°")
    
    st.divider()

    st.subheader("3. è¾“å…¥æ•°æ®")
    user_input = st.text_input("è¾“å…¥æ–‡æœ¬ (ç©ºæ ¼åˆ†éš”)", "I love LLM", help="å°è¯•è¾“å…¥ä¸åŒçš„å¥å­é•¿åº¦")
    tokens = user_input.split()
    seq_len = len(tokens)

    st.success(f"ğŸ“Š å½“å‰é…ç½®:\n- åºåˆ—é•¿åº¦: {seq_len}\n- å¤´ç»´åº¦: {d_k}")
    st.caption("Powered by Streamlit & Manim")

# ==========================================
# ä¸»ç•Œé¢ï¼šé€‰é¡¹å¡
# ==========================================
tab1, tab2, tab3 = st.tabs(["ğŸ¥ æ ¸å¿ƒåŸç†åŠ¨ç”» (Manim)", "ğŸ§® äº¤äº’å¼è®¡ç®—å®éªŒå®¤", "ğŸ§Š Attention çƒ­åŠ›å›¾"])

# -----------------------------------------------------------------------------
# Tab 1: Manim åŠ¨ç”»å½±é™¢ (å®Œæ•´æ”¶å½• 6 ä¸ªåœºæ™¯)
# -----------------------------------------------------------------------------
with tab1:
    anim_choice = st.radio(
        "é€‰æ‹©è§‚æµ‹å¯¹è±¡:",
        [
            "1. åŸºç¡€æ³¨æ„åŠ› (Dot-Product)", 
            "2. Encoder æ¶æ„ (Residual)", 
            "3. Decoder æ©ç  (Masking)", 
            "4. åä½œæœºåˆ¶ (Cross-Attention)",
            "5. å·…å³°å¯¹å†³ (O(L^2) vs O(L))",
            "6. Mamba æ ¸å¿ƒ (Selective Scan)" 
        ],
        horizontal=True
    )
    
    st.divider()
    col_video, col_text = st.columns([1.8, 1])

    # === åœºæ™¯ 1: åŸºç¡€æ³¨æ„åŠ› ===
    if "1." in anim_choice:
        with col_video:
            try: st.video("assets/Attention.mp4")
            except: st.error("è¯·ç¡®ä¿ assets/Attention.mp4 å­˜åœ¨")
        with col_text:
            st.subheader("ğŸ” æ·±åº¦è§£æ")
            st.markdown("""
            **Transformer çš„åŸå­æ“ä½œï¼šè®¡ç®—ç›¸å…³æ€§ã€‚**
            1. **å¸ƒå±€**: å·¦ä¾§ $Q$ (Query)ï¼Œä¸Šæ–¹ $K^T$ (Key)ã€‚
            2. **ç‚¹ç§¯**: è§†é¢‘ä¸­**é»„è‰²é«˜äº®**æ‰«æå¤„ï¼Œè®¡ç®—å‘é‡å¤¹è§’ã€‚å¤¹è§’è¶Šå°ï¼Œåˆ†æ•°è¶Šé«˜ã€‚
            3. **Softmax**: çŸ©é˜µå˜çº¢ï¼Œä»£è¡¨æ¦‚ç‡åˆ†å¸ƒã€‚æ¯ä¸€è¡Œæ¦‚ç‡å’Œä¸º 1ã€‚
            """)

    # === åœºæ™¯ 2: Encoder ===
    elif "2." in anim_choice:
        with col_video:
            try: st.video("assets/EncoderFlow.mp4")
            except: st.error("è¯·ç¡®ä¿ assets/EncoderFlow.mp4 å­˜åœ¨")
        with col_text:
            st.subheader("ğŸ” æ·±åº¦è§£æ")
            st.markdown("""
            **Encoder çš„å®è§‚æ•°æ®æµã€‚**
            1. **å¤šå¤´åˆ†è£‚**: Input åˆ†è£‚ä¸º Q, K, Vï¼Œå†åˆ†è£‚ä¸ºå¤šä¸ª Headã€‚
            2. **æ®‹å·®è¿æ¥**: æ³¨æ„é‚£æ¡å·¨å¤§çš„**é»„è‰²å¼§çº¿**ã€‚å®ƒæ˜¯æ¢¯åº¦çš„â€œé«˜é€Ÿå…¬è·¯â€ï¼Œé˜²æ­¢æ·±å±‚ç½‘ç»œæ¢¯åº¦æ¶ˆå¤±ã€‚
            """)

    # === åœºæ™¯ 3: Decoder ===
    elif "3." in anim_choice:
        with col_video:
            try: st.video("assets/DecoderMasking.mp4")
            except: st.error("è¯·ç¡®ä¿ assets/DecoderMasking.mp4 å­˜åœ¨")
        with col_text:
            st.subheader("ğŸ” æ·±åº¦è§£æ")
            st.markdown("""
            **Decoder çš„æ—¶é—´æœºå™¨é”ã€‚**
            1. **Mask é™ä¸´**: å³ä¸Šè§’å˜æˆ <font color='red'>çº¢è‰² -inf</font>ï¼Œä»£è¡¨â€œæœªæ¥â€ã€‚
            2. **Softmax å½’é›¶**: `-inf` ç»è¿‡ Softmax å˜ä¸º **0** (é»‘è‰²)ã€‚è¿™ç‰©ç†åˆ‡æ–­äº†é€šå‘æœªæ¥çš„è§†çº¿ï¼Œç¡®ä¿è‡ªå›å½’ç”Ÿæˆã€‚
            """, unsafe_allow_html=True)

    # === åœºæ™¯ 4: Cross-Attention ===
    elif "4." in anim_choice:
        with col_video:
            try: st.video("assets/CrossAttentionFlow.mp4")
            except: st.error("è¯·ç¡®ä¿ assets/CrossAttentionFlow.mp4 å­˜åœ¨")
        with col_text:
            st.subheader("ğŸ” æ·±åº¦è§£æ")
            st.markdown("""
            **Encoder ä¸ Decoder çš„å¯¹è¯ã€‚**
            1. **è§’è‰²**: å·¦ä¾§ Encoder æä¾›çŸ¥è¯†åº“ (K, V)ï¼Œå³ä¾§ Decoder æ‹¿ç€é—®é¢˜ (Q)ã€‚
            2. **ä¸‰æ­¥èµ°**: Q æ‰«æ K $\\to$ ç”Ÿæˆæƒé‡ $\\to$ æå– V $\\to$ èåˆã€‚
            """)

    # === åœºæ™¯ 5: Transformer vs Mamba ===
    elif "5." in anim_choice:
        with col_video:
            try: st.video("assets/TransformerVsMamba.mp4")
            except: st.error("è¯·ç¡®ä¿ assets/TransformerVsMamba.mp4 å­˜åœ¨")
        with col_text:
            st.subheader("âš”ï¸ å·…å³°å¯¹å†³ï¼šå¤æ‚åº¦")
            st.markdown("""
            **$O(L^2)$ vs $O(L)$ çš„ç›´è§‚å·®å¼‚ã€‚**
            1. **å·¦ä¾§ (Transformer)**: éšç€åºåˆ—å˜é•¿ï¼ŒçŸ©é˜µé¢ç§¯å‘ˆ**å¹³æ–¹çº§çˆ†ç‚¸**ã€‚æ˜¾å­˜è¿…é€Ÿè€—å°½ã€‚
            2. **å³ä¾§ (Mamba)**: æ— è®ºåºåˆ—å¤šé•¿ï¼Œå®ƒçš„é«˜åº¦ (State Dim) æ˜¯å›ºå®šçš„ï¼æ¨ç†æ˜¾å­˜æ’å®šã€‚
            """)

    # === åœºæ™¯ 6: Mamba æ ¸å¿ƒ ===
    elif "6." in anim_choice:
        with col_video:
            try: st.video("assets/MambaMechanism.mp4")
            except: st.error("è¯·ç¡®ä¿ assets/MambaMechanism.mp4 å­˜åœ¨")
        with col_text:
            st.subheader("ğŸ Mamba: é€‰æ‹©æ€§æœºåˆ¶")
            st.markdown(r"""
            **æ ¸å¿ƒå…¬å¼**: $h_t = \bar{A}_t h_{t-1} + \bar{B}_t x_t$
            
            1. **åŠ¨æ€é˜€é—¨**: $\bar{A}, \bar{B}$ æ˜¯**éšè¾“å…¥å˜åŒ–çš„**ã€‚
            2. **ç°è±¡**:
               - <font color='red'>Noise</font>: é˜€é—¨å…³é—­ï¼Œè®°å¿†è¡°å‡ã€‚
               - <font color='green'>Key Info</font>: é˜€é—¨å¤§å¼€ï¼Œå¼ºåŠ›å†™å…¥ã€‚
            """, unsafe_allow_html=True)

# -----------------------------------------------------------------------------
# Tab 2: äº¤äº’å¼è®¡ç®— (åŒæ ¸é©±åŠ¨ï¼šTransformer + Mamba)
# -----------------------------------------------------------------------------
with tab2:
    st.header("ğŸ§® ç®—æ³•å†…æ ¸æ¨å¯¼")
    
    # é€‰æ‹©å†…æ ¸
    model_type = st.selectbox("é€‰æ‹©æ¨¡å‹å†…æ ¸:", ["Transformer (Self-Attention)", "Mamba (Selective Scan)"])
    
    # === Transformer æ¨¡å— (ä¿ç•™åŸé€»è¾‘) ===
    if model_type == "Transformer (Self-Attention)":
        st.subheader("1. Input Embedding (éšæœºåˆå§‹åŒ–)")
        torch.manual_seed(42)
        X = torch.randn(seq_len, d_model)
        
        df_x = pd.DataFrame(X.numpy(), index=tokens, columns=[f"d_{i}" for i in range(d_model)])
        st.dataframe(df_x.style.background_gradient(cmap="Blues", axis=None), use_container_width=True)
        
        st.subheader("2. Linear Projections")
        col_q, col_k = st.columns(2)
        
        W_q = torch.randn(d_model, d_k)
        W_k = torch.randn(d_model, d_k)
        
        Q = X @ W_q
        K = X @ W_k
        
        with col_q:
            st.markdown(f"**Query Matrix ($X \\times W_Q$)** shape: `{Q.shape}`")
            st.dataframe(pd.DataFrame(Q.numpy(), index=tokens).style.background_gradient(cmap="Reds", axis=None))
        with col_k:
            st.markdown(f"**Key Matrix ($X \\times W_K$)** shape: `{K.shape}`")
            st.dataframe(pd.DataFrame(K.numpy(), index=tokens).style.background_gradient(cmap="Greens", axis=None))

        st.subheader("3. Scaled Dot-Product Attention")
        latex_formula = r"Attention(Q, K) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)"
        st.latex(latex_formula)
        
        raw_scores = Q @ K.T
        scaled_scores = raw_scores / np.sqrt(d_k)
        
        st.write("**Scaled Scores Matrix** (Softmax ä¹‹å‰):")
        st.dataframe(pd.DataFrame(scaled_scores.numpy(), index=tokens, columns=tokens).style.background_gradient(cmap="coolwarm", axis=None))
        
        # ä¿å­˜ç”¨äº Tab 3
        st.session_state['transformer_scores'] = scaled_scores

    # === Mamba æ¨¡å— (ä¿®å¤ç‰ˆ) ===
    elif model_type == "Mamba (Selective Scan)":
        st.subheader("ğŸ Mamba é€’å½’æ‰«ææ¨¡æ‹Ÿ")
        st.markdown(r"æ‰‹åŠ¨æ¨¡æ‹Ÿ RNN æ¨¡å¼æ¨ç†ï¼Œè§‚å¯Ÿ Hidden State ($h$) çš„æ¼”å˜ã€‚")
        
        np.random.seed(42)
        inputs = np.random.randn(seq_len, d_model)
        
        # ç®€åŒ–çš„å‚æ•°åˆå§‹åŒ–
        A = -np.exp(np.random.randn(d_model, d_state)) # A < 0 ä¿è¯ç¨³å®š
        h_t = np.zeros((d_model, d_state)) # åˆå§‹çŠ¶æ€
        
        history = []
        cols = st.columns(min(seq_len, 4)) # æœ€å¤šå±•ç¤ºå‰4æ­¥
        
        for t in range(seq_len):
            x_t = inputs[t] # shape: (d_model,)
            
            # æ¨¡æ‹Ÿå‚æ•°ç”Ÿæˆ (Linear projections)
            # delta_t shape: (d_model,)
            delta_t = np.log(1 + np.exp(np.dot(x_t, np.random.randn(d_model, d_model)))) 
            
            # B_t shape: (d_model, d_state)
            B_t = np.random.randn(d_model, d_state)
            
            # === ä¿®å¤æ ¸å¿ƒé€»è¾‘ ===
            # å°† delta_t å˜æˆåˆ—å‘é‡ (d_model, 1)ï¼Œä»¥ä¾¿å¹¿æ’­
            delta_t_col = delta_t[:, None]
            
            # ç¦»æ•£åŒ– (Discretization)
            bar_A = np.exp(delta_t_col * A)        # (D, 1) * (D, N) -> (D, N)
            bar_B = delta_t_col * B_t              # (D, 1) * (D, N) -> (D, N)
            
            # é€’å½’æ›´æ–° (Recurrence)
            # x_t éœ€è¦å˜æˆ (D, 1) æ‰èƒ½ä¹˜åˆ° bar_B ä¸Š
            h_t = bar_A * h_t + bar_B * x_t[:, None]
            
            history.append(h_t.flatten())
            
            # å¯è§†åŒ–å‰å‡ æ­¥
            if t < 4:
                with cols[t]:
                    # å®‰å…¨è·å– token
                    curr_token = tokens[t] if t < len(tokens) else f"T{t}"
                    st.caption(f"Time t={t+1}: '{curr_token}'")
                    
                    st.metric("Gate $\Delta$ (Mean)", f"{np.mean(delta_t):.2f}")
                    
                    fig_h = px.imshow(h_t, color_continuous_scale="Magma", title=f"State $h_{t}$")
                    fig_h.update_layout(height=200, margin=dict(l=0,r=0,t=30,b=0))
                    fig_h.update_xaxes(showticklabels=False)
                    fig_h.update_yaxes(showticklabels=False)
                    st.plotly_chart(fig_h, use_container_width=True)
        
        st.subheader("ğŸ“Š è®°å¿†æ¼”å˜è½¨è¿¹")
        st.caption("å±•ç¤ºéšçŠ¶æ€ä¸­å‰10ä¸ªç»´åº¦çš„æ•°å€¼å˜åŒ–ã€‚å¯ä»¥çœ‹åˆ°æœ‰äº›çŠ¶æ€è¢«ä¿æŒï¼Œæœ‰äº›è¢«é—å¿˜ã€‚")
        
        # è½¬æ¢æ•°æ®ä»¥ä¾¿ç»˜å›¾
        hist_data = np.array(history)[:, :10] # å–å‰10ä¸ªç‰¹å¾
        chart_data = pd.DataFrame(
            hist_data, 
            index=[f"t={i+1}" for i in range(seq_len)]
        )
        st.line_chart(chart_data)
        
        st.success(f"""
        **å…³é”®ç»“è®º**:
        æ— è®ºåºåˆ—é•¿åº¦ $L$ æ˜¯ {seq_len} è¿˜æ˜¯ 10000:
        1. æˆ‘ä»¬åªéœ€è¦ç»´æŠ¤ **1 ä¸ª** çŸ©é˜µ $h_t$ (å°ºå¯¸ {d_model}x{d_state})ã€‚
        2. ä¸‹ä¸€æ­¥è®¡ç®—åªä¾èµ–äº $h_t$ å’Œ $x_{{t+1}}$ã€‚
        3. **æ˜¾å­˜å ç”¨æ’å®šä¸º $O(1)$** (ä¸ $L$ æ— å…³)ã€‚
        """)

# -----------------------------------------------------------------------------
# Tab 3: çƒ­åŠ›å›¾ (ä»…é€‚ç”¨äº Transformer)
# -----------------------------------------------------------------------------
with tab3:
    st.header("ğŸ§Š æœ€ç»ˆæ³¨æ„åŠ›å›¾ (Attention Map)")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ Transformer çš„è®¡ç®—ç»“æœ
    if 'transformer_scores' in st.session_state:
        scores = st.session_state['transformer_scores']
        attn_weights = F.softmax(scores, dim=-1)
        
        c1, c2 = st.columns([3, 1])
        with c1:
            fig = px.imshow(
                attn_weights.numpy(),
                x=tokens, y=tokens,
                labels=dict(x="Key (è¢«å…³æ³¨)", y="Query (æŸ¥è¯¢)", color="æ¦‚ç‡"),
                color_continuous_scale="Viridis",
                text_auto=".2f", aspect="auto"
            )
            st.plotly_chart(fig, use_container_width=True)
        with c2:
            st.info("ğŸ’¡ **è§£è¯»**")
            st.markdown("* å¯¹è§’çº¿é¢œè‰²æ·±ï¼šå…³æ³¨è‡ªå·±ã€‚\n* æ¯ä¸€è¡Œæ¦‚ç‡å’Œä¸º 1.0ã€‚")
    else:
        st.warning("âš ï¸ è¯·å…ˆåœ¨ Tab 2 ä¸­é€‰æ‹© 'Transformer' å¹¶è¿è¡Œä¸€æ¬¡è®¡ç®—ã€‚")