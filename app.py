import streamlit as st
import numpy as np
import torch
import torch.nn.functional as F
import plotly.express as px
import pandas as pd

# ==========================================
# é¡µé¢é…ç½®
# ==========================================
st.set_page_config(
    page_title="Transformer & Mamba æ·±åº¦è§£æ",
    page_icon="ğŸ§¬",
    layout="wide",
    initial_sidebar_state="expanded",
)

# CSS ç¾åŒ–
st.markdown(
    """
<style>
    .math-box {
        background-color: #f8f9fa;
        border-left: 5px solid #ff4b4b;
        padding: 15px;
        margin-bottom: 20px;
        border-radius: 5px;
    }
    .analogy-box {
        background-color: #e8f5e9;
        border-left: 5px solid #66bb6a;
        padding: 15px;
        border-radius: 5px;
        margin-bottom: 10px;
    }
</style>
""",
    unsafe_allow_html=True,
)

st.title("ğŸ¤– Transformer vs ğŸ Mambaï¼šæ ¸å¿ƒæœºåˆ¶å¯è§†åŒ–")
st.markdown("ä»å®è§‚åŠ¨ç”»åˆ°å¾®è§‚æ•°å­¦ï¼šä¸¥è°¨è¿˜åŸç®—æ³•ç»†èŠ‚ã€‚")

# ==========================================
# å·¦ä¾§è¾¹æ ï¼šç»Ÿä¸€å‚æ•°æ§åˆ¶ (ä¿ç•™)
# ==========================================
with st.sidebar:
    st.header("âš™ï¸ å®éªŒå®¤è®¾ç½®")

    st.subheader("1. Transformer å‚æ•°")
    d_model = st.slider("åµŒå…¥ç»´åº¦ (d_model)", 4, 32, 8, step=4)
    n_heads = st.radio("å¤šå¤´æ•°é‡ (Heads)", [1, 2, 4], index=1)
    d_k = d_model // n_heads

    st.divider()

    st.subheader("2. Mamba å‚æ•°")
    d_state = st.slider("çŠ¶æ€ç»´åº¦ (d_state/N)", 2, 16, 4, help="SSM éšçŠ¶æ€æ°´ç®±çš„å¤§å°")

    st.divider()

    st.subheader("3. è¾“å…¥æ•°æ®")
    user_input = st.text_input(
        "è¾“å…¥æ–‡æœ¬ (ç©ºæ ¼åˆ†éš”)", "I love LLM", help="å°è¯•è¾“å…¥ä¸åŒçš„å¥å­é•¿åº¦"
    )
    tokens = user_input.split()
    seq_len = len(tokens)

    st.success(
        f"ğŸ“Š å½“å‰é…ç½®:\n- åºåˆ—é•¿åº¦: {seq_len}\n- å¤´ç»´åº¦: {d_k}\n- çŠ¶æ€ç»´åº¦: {d_state}"
    )

# ==========================================
# ä¸»ç•Œé¢ï¼šé€‰é¡¹å¡
# ==========================================
tab1, tab2, tab3 = st.tabs(
    ["ğŸ¥ æ ¸å¿ƒåŸç†åŠ¨ç”» (Manim)", "ğŸ§® äº¤äº’å¼æ•°å­¦å®éªŒå®¤", "ğŸ§Š Attention çƒ­åŠ›å›¾"]
)

# -----------------------------------------------------------------------------
# Tab 1: Manim åŠ¨ç”»å½±é™¢ (å¸ƒå±€å¤§é‡æ„ï¼šæ‹†åˆ†ä¸ºå­æ ‡ç­¾é¡µ)
# -----------------------------------------------------------------------------
with tab1:
    st.info("ğŸ’¡ è¯·ç‚¹å‡»ä¸‹æ–¹å­æ ‡ç­¾åˆ‡æ¢ä¸åŒæ¶æ„çš„æ¼”ç¤ºã€‚")

    # === ä½¿ç”¨å­æ ‡ç­¾é¡µè¿›è¡Œç‰©ç†éš”ç¦» ===
    sub_tf, sub_vs, sub_mamba = st.tabs(
        ["ğŸ¤– Transformer å®¶æ—", "âš”ï¸ æ¶æ„å¯¹æ¯”", "ğŸ Mamba å®¶æ—"]
    )

    # --- 1. Transformer ä¸“åŒº ---
    with sub_tf:
        tf_choice = st.radio(
            "é€‰æ‹© Transformer ç»„ä»¶:",
            [
                "1. åŸºç¡€æ³¨æ„åŠ› (Dot-Product)",
                "2. Encoder æ¶æ„ (Residual)",
                "3. Decoder æ©ç  (Masking)",
                "4. åä½œæœºåˆ¶ (Cross-Attention)",
            ],
            horizontal=True,
        )
        st.divider()
        col_v, col_t = st.columns([1.8, 1])

        if "1." in tf_choice:
            with col_v:
                try:
                    st.video("assets/Attention.mp4")
                except:
                    st.error("ç¼ºæ–‡ä»¶: assets/Attention.mp4")
            with col_t:
                st.subheader("ğŸ” åŸºç¡€æ³¨æ„åŠ›è§£æ")
                st.markdown(
                    """
                **Transformer çš„åŸå­æ“ä½œï¼šè®¡ç®—ç›¸å…³æ€§ã€‚**
                1. **å¸ƒå±€**: å·¦ä¾§ $Q$ (Query)ï¼Œä¸Šæ–¹ $K^T$ (Key)ã€‚
                2. **ç‚¹ç§¯**: è§†é¢‘ä¸­**é»„è‰²é«˜äº®**æ‰«æå¤„ï¼Œè®¡ç®—å‘é‡å¤¹è§’ã€‚
                3. **Softmax**: çŸ©é˜µå˜çº¢ï¼Œä»£è¡¨æ¦‚ç‡åˆ†å¸ƒã€‚
                """
                )
        elif "2." in tf_choice:
            with col_v:
                try:
                    st.video("assets/EncoderFlow.mp4")
                except:
                    st.error("ç¼ºæ–‡ä»¶: assets/EncoderFlow.mp4")
            with col_t:
                st.subheader("ğŸ” Encoder è§£æ")
                st.markdown(
                    """
                **å®è§‚æ•°æ®æµå‘ã€‚**
                1. **å¤šå¤´åˆ†è£‚**: Input åˆ†è£‚ä¸º Q, K, Vï¼Œå†åˆ†è£‚ä¸ºå¤šä¸ª Headã€‚
                2. **æ®‹å·®è¿æ¥**: å·¨å¤§çš„**é»„è‰²å¼§çº¿**ã€‚å®ƒæ˜¯æ¢¯åº¦çš„â€œé«˜é€Ÿå…¬è·¯â€ã€‚
                """
                )
        elif "3." in tf_choice:
            with col_v:
                try:
                    st.video("assets/DecoderMasking.mp4")
                except:
                    st.error("ç¼ºæ–‡ä»¶: assets/DecoderMasking.mp4")
            with col_t:
                st.subheader("ğŸ” Decoder Mask è§£æ")
                st.markdown(
                    """
                **æ—¶é—´æœºå™¨é”ã€‚**
                1. **Mask é™ä¸´**: å³ä¸Šè§’å˜æˆ <font color='red'>-inf</font>ã€‚
                2. **Softmax å½’é›¶**: ç‰©ç†åˆ‡æ–­äº†é€šå‘æœªæ¥çš„è§†çº¿ã€‚
                """,
                    unsafe_allow_html=True,
                )
        elif "4." in tf_choice:
            with col_v:
                try:
                    st.video("assets/CrossAttentionFlow.mp4")
                except:
                    st.error("ç¼ºæ–‡ä»¶: assets/CrossAttentionFlow.mp4")
            with col_t:
                st.subheader("ğŸ” Cross-Attention è§£æ")
                st.markdown(
                    """
                **Encoder ä¸ Decoder çš„å¯¹è¯ã€‚**
                1. **è§’è‰²**: å·¦ä¾§ Encoder æä¾›çŸ¥è¯†åº“ (K, V)ï¼Œå³ä¾§ Decoder æ‹¿ç€é—®é¢˜ (Q)ã€‚
                2. **æµç¨‹**: Q æ‰«æ K $\\to$ ç”Ÿæˆæƒé‡ $\\to$ æå– Vã€‚
                """
                )

    # --- 2. å¯¹æ¯”ä¸“åŒº ---
    with sub_vs:
        st.subheader("âš”ï¸ å·…å³°å¯¹å†³ï¼šå¤æ‚åº¦å¯è§†åŒ–")
        col_v_vs, col_t_vs = st.columns([1.8, 1])
        with col_v_vs:
            try:
                st.video("assets/TransformerVsMamba.mp4")
            except:
                st.error("ç¼ºæ–‡ä»¶: assets/TransformerVsMamba.mp4")
        with col_t_vs:
            st.markdown(
                """
            **$O(L^2)$ vs $O(L)$ çš„ç›´è§‚å·®å¼‚**
            
            **å·¦ä¾§ (Transformer)**: 
            * éšç€åºåˆ—å˜é•¿ï¼ŒçŸ©é˜µé¢ç§¯å‘ˆ**å¹³æ–¹çº§çˆ†ç‚¸**ã€‚
            * å¤„ç†é•¿æ–‡æ—¶æ˜¾å­˜è¿…é€Ÿè€—å°½ã€‚
            
            **å³ä¾§ (Mamba)**: 
            * æ— è®ºåºåˆ—å¤šé•¿ï¼Œå®ƒçš„é«˜åº¦ (State Dim) æ˜¯å›ºå®šçš„ï¼
            * æ¨ç†æ˜¾å­˜æ’å®š $O(1)$ã€‚
            """
            )

    # --- 3. Mamba ä¸“åŒº ---
    with sub_mamba:
        mamba_choice = st.radio(
            "é€‰æ‹© Mamba ç»„ä»¶:",
            ["1. Mamba æ ¸å¿ƒæœºåˆ¶ (Selective Scan)", "2. æ•°å­¦åŸºç¡€ (Discretization)"],
            horizontal=True,
        )
        st.divider()
        col_v_m, col_t_m = st.columns([1.8, 1])

        if "1." in mamba_choice:
            with col_v_m:
                try:
                    st.video("assets/MambaMechanism.mp4")
                except:
                    st.error("ç¼ºæ–‡ä»¶: assets/MambaMechanism.mp4")
            with col_t_m:
                st.subheader("ğŸ é€‰æ‹©æ€§é—å¿˜æœºåˆ¶")
                st.markdown(
                    r"""
                **æ ¸å¿ƒå…¬å¼**: $h_t = \bar{A}_t h_{t-1} + \bar{B}_t x_t$
                
                **ç°è±¡è§£æ**:
                * **åŠ¨æ€é˜€é—¨**: $\bar{A}, \bar{B}$ æ˜¯éšè¾“å…¥å˜åŒ–çš„ã€‚
                * **Noise (çº¢)**: é˜€é—¨å…³é—­ï¼Œè®°å¿†è¡°å‡ã€‚
                * **Key Info (ç»¿)**: é˜€é—¨å¤§å¼€ï¼Œå¼ºåŠ›å†™å…¥ã€‚
                """
                )
        elif "2." in mamba_choice:
            with col_v_m:
                try:
                    st.video("assets/DiscretizationVisual.mp4")
                except:
                    st.error("ç¼ºæ–‡ä»¶: assets/DiscretizationVisual.mp4")
            with col_t_m:
                st.subheader("ğŸ æ•°å­¦æ¡¥æ¢ï¼šç¦»æ•£åŒ–")
                st.markdown(
                    r"""
                **ä»è¿ç»­ç‰©ç†åˆ°æ•°å­—ä¿¡å·**
                
                1. **ZOH (é›¶é˜¶ä¿æŒ)**: å‡è®¾åœ¨ $\Delta$ æ—¶é—´å†…è¾“å…¥ä¸å˜ã€‚
                2. **$\Delta$ (æ­¥é•¿)**: 
                   * $\Delta$ å¤§ $\to$ æ›´å¤šé—å¿˜ï¼Œæ›´å¤šå†™å…¥ã€‚
                   * $\Delta$ å° $\to$ ä¿æŒçŠ¶æ€ã€‚
                """
                )

# -----------------------------------------------------------------------------
# Tab 2: äº¤äº’å¼è®¡ç®— (ä¿æŒåŸæ ·ï¼Œå«å…¬å¼æ¨å¯¼)
# -----------------------------------------------------------------------------
with tab2:
    st.header("ğŸ§® ç®—æ³•å†…æ ¸æ¨å¯¼")
    st.caption("è¿™é‡Œä¸ä»…æœ‰ä»£ç è¿è¡Œç»“æœï¼Œè¿˜æœ‰æ¯ä¸€æ­¥èƒŒåçš„æ•°å­¦å…¬å¼ã€‚")

    # é€‰æ‹©å†…æ ¸
    model_type = st.selectbox(
        "é€‰æ‹©æ¨¡å‹å†…æ ¸è¿›è¡Œæ¨å¯¼:",
        ["Transformer (Self-Attention)", "Mamba (Selective Scan)"],
    )

    # =========================================================
    # Transformer æ¨¡å—
    # =========================================================
    if model_type == "Transformer (Self-Attention)":

        # --- æ•°å­¦åŸç†åŒº ---
        st.markdown('<div class="math-box">', unsafe_allow_html=True)
        st.markdown("### ğŸ“ æ ¸å¿ƒå…¬å¼ï¼šScaled Dot-Product Attention")
        st.latex(
            r"\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V"
        )
        st.markdown(
            """
        * **Q (Query)**: æŸ¥è¯¢å‘é‡ï¼Œä»£è¡¨å½“å‰ Token æƒ³æ‰¾ä»€ä¹ˆã€‚
        * **K (Key)**: é”®å‘é‡ï¼Œä»£è¡¨è¢«æŸ¥è¯¢ Token çš„ç‰¹å¾æ ‡ç­¾ã€‚
        * **V (Value)**: å€¼å‘é‡ï¼Œä»£è¡¨å®é™…åŒ…å«çš„ä¿¡æ¯å†…å®¹ã€‚
        * **$\sqrt{d_k}$**: ç¼©æ”¾å› å­ï¼Œé˜²æ­¢ç‚¹ç§¯è¿‡å¤§å¯¼è‡´æ¢¯åº¦æ¶ˆå¤±ã€‚
        """
        )
        st.markdown("</div>", unsafe_allow_html=True)

        # --- ä»£ç äº¤äº’åŒº ---
        st.subheader("1. Input Embedding (éšæœºåˆå§‹åŒ–)")
        torch.manual_seed(42)
        X = torch.randn(seq_len, d_model)
        df_x = pd.DataFrame(
            X.numpy(), index=tokens, columns=[f"d_{i}" for i in range(d_model)]
        )
        st.dataframe(
            df_x.style.background_gradient(cmap="Blues", axis=None), height=150
        )

        st.subheader("2. Linear Projections ($W_Q, W_K, W_V$)")
        col_q, col_k = st.columns(2)
        W_q = torch.randn(d_model, d_k)
        W_k = torch.randn(d_model, d_k)
        W_v = torch.randn(d_model, d_model)  # Fix: W_v added

        Q = X @ W_q
        K = X @ W_k
        V = X @ W_v  # Fix: V added

        with col_q:
            st.markdown("**Query Matrix ($Q = XW_Q$)**")
            st.dataframe(
                pd.DataFrame(Q.numpy(), index=tokens).style.background_gradient(
                    cmap="Reds", axis=None
                ),
                height=150,
            )
        with col_k:
            st.markdown("**Key Matrix ($K = XW_K$)**")
            st.dataframe(
                pd.DataFrame(K.numpy(), index=tokens).style.background_gradient(
                    cmap="Greens", axis=None
                ),
                height=150,
            )

        st.subheader("3. Attention Scores & Softmax")
        c1, c2 = st.columns([1, 1])
        with c1:
            st.markdown(r"**Raw Scores**: $S = QK^T$")
            raw_scores = Q @ K.T
            st.dataframe(
                pd.DataFrame(
                    raw_scores.numpy(), index=tokens, columns=tokens
                ).style.background_gradient(cmap="coolwarm", axis=None)
            )
        with c2:
            st.markdown(r"**Probabilities**: $P = \text{softmax}(S / \sqrt{d_k})$")
            scaled_scores = raw_scores / np.sqrt(d_k)
            attn_weights = F.softmax(scaled_scores, dim=-1)
            st.dataframe(
                pd.DataFrame(
                    attn_weights.numpy(), index=tokens, columns=tokens
                ).style.background_gradient(cmap="Oranges", axis=None)
            )

        # ä¿å­˜ç”¨äº Tab 3
        st.session_state["transformer_scores"] = scaled_scores
        st.subheader("4. Final Output ($Z = P \cdot V$)")
        output_z = attn_weights @ V
        st.dataframe(
            pd.DataFrame(output_z.numpy(), index=tokens).style.background_gradient(
                cmap="Purples", axis=None
            )
        )

    # =========================================================
    # Mamba æ¨¡å—
    # =========================================================
    elif model_type == "Mamba (Selective Scan)":

        # --- æ•°å­¦åŸç†åŒº ---
        st.markdown('<div class="math-box">', unsafe_allow_html=True)
        st.markdown("### ğŸ“ æ ¸å¿ƒå…¬å¼ï¼šSelective SSM")
        st.markdown("**1. è¿ç»­ç³»ç»Ÿ (Continuous)**")
        st.latex(r"h'(t) = \mathbf{A}h(t) + \mathbf{B}x(t)")

        st.markdown("**2. ç¦»æ•£åŒ– (Discretization) - Zero Order Hold**")
        c_math1, c_math2 = st.columns(2)
        with c_math1:
            st.latex(r"\bar{A} = \exp(\Delta \cdot \mathbf{A})")
        with c_math2:
            st.latex(r"\bar{B} \approx \Delta \cdot \mathbf{B}")

        st.markdown("**3. é€’å½’æ¨ç† (Recurrence)**")
        st.latex(r"h_t = \bar{A}_t h_{t-1} + \bar{B}_t x_t")
        st.warning("å…³é”®ï¼š$\Delta, \bar{B}$ éšè¾“å…¥ $x_t$ å˜åŒ–ï¼")
        st.markdown("</div>", unsafe_allow_html=True)

        # --- ä»£ç äº¤äº’åŒº ---
        st.subheader("ğŸ Mamba é€æ­¥é€’å½’æ¨¡æ‹Ÿ")

        np.random.seed(42)
        # åˆå§‹åŒ–å‚æ•°
        A_fixed = -np.exp(np.random.randn(d_model, d_state))
        B_fixed = np.random.randn(d_model, d_state)
        W_delta = np.random.randn(d_model, d_model)

        inputs = np.random.randn(seq_len, d_model)
        h_t = np.zeros((d_model, d_state))

        history_h = []
        history_delta = []

        # é€æ­¥å±•ç¤º
        cols = st.columns(min(seq_len, 4))

        for t in range(seq_len):
            x_t = inputs[t]

            # 1. è®¡ç®— Delta
            delta_val = np.log(1 + np.exp(x_t @ W_delta))

            # 2. ç¦»æ•£åŒ–
            delta_col = delta_val[:, None]
            bar_A = np.exp(delta_col * A_fixed)
            bar_B = delta_col * B_fixed

            # 3. é€’å½’æ›´æ–°
            x_t_col = x_t[:, None]
            h_next = bar_A * h_t + bar_B * x_t_col

            history_h.append(h_next.flatten())
            history_delta.append(delta_val.mean())

            # å‰å‡ æ­¥çš„å¯è§†åŒ–
            if t < 4:
                with cols[t]:
                    curr_token = tokens[t] if t < len(tokens) else f"T{t}"
                    st.markdown(f"**Step {t+1}: {curr_token}**")
                    st.metric("Avg $\Delta$", f"{np.mean(delta_val):.2f}")

                    fig_cell = px.imshow(
                        h_next, color_continuous_scale="Magma", title="State $h_t$"
                    )
                    fig_cell.update_layout(
                        height=150,
                        margin=dict(l=0, r=0, t=30, b=0),
                        coloraxis_showscale=False,
                    )
                    fig_cell.update_xaxes(showticklabels=False)
                    fig_cell.update_yaxes(showticklabels=False)
                    st.plotly_chart(fig_cell, use_container_width=True)

            h_t = h_next

        st.subheader("ğŸ“Š è®°å¿†æ¼”å˜ä¸é—¨æ§åˆ†æ")
        col_chart1, col_chart2 = st.columns([2, 1])

        with col_chart1:
            st.markdown("**1. éšçŠ¶æ€ (Memory) éšæ—¶é—´å˜åŒ–**")
            hist_data = np.array(history_h)[:, :20]
            fig_hist = px.imshow(
                hist_data.T,
                aspect="auto",
                color_continuous_scale="Magma",
                labels=dict(x="Time", y="Dim"),
            )
            st.plotly_chart(fig_hist, use_container_width=True)

        with col_chart2:
            st.markdown("**2. $\Delta$ (æ­¥é•¿) æ³¢åŠ¨**")
            st.caption("$\Delta$ è¶Šå¤§ï¼Œä»£è¡¨å½“å‰ Token è¶Šé‡è¦ï¼ˆè¢«å†™å…¥è¶Šå¤šï¼‰ã€‚")
            st.line_chart(history_delta)

# -----------------------------------------------------------------------------
# Tab 3: çƒ­åŠ›å›¾ (ä¿æŒåŸæ ·)
# -----------------------------------------------------------------------------
with tab3:
    st.header("ğŸ§Š æœ€ç»ˆæ³¨æ„åŠ›å›¾ (Attention Map)")

    if "transformer_scores" in st.session_state:
        scores = st.session_state["transformer_scores"]
        attn_weights = F.softmax(scores, dim=-1)

        c1, c2 = st.columns([3, 1])
        with c1:
            fig = px.imshow(
                attn_weights.numpy(),
                x=tokens,
                y=tokens,
                labels=dict(x="Key", y="Query", color="Prob"),
                color_continuous_scale="Viridis",
                text_auto=".2f",
                aspect="auto",
            )
            st.plotly_chart(fig, use_container_width=True)
        with c2:
            st.info("ğŸ’¡ **è§£è¯»**")
            st.markdown("* å¯¹è§’çº¿é¢œè‰²æ·±ï¼šå…³æ³¨è‡ªå·±ã€‚\n* æ¯ä¸€è¡Œæ¦‚ç‡å’Œä¸º 1.0ã€‚")
    else:
        st.warning("âš ï¸ è¯·å…ˆåœ¨ Tab 2 ä¸­é€‰æ‹© 'Transformer' å¹¶è¿è¡Œä¸€æ¬¡è®¡ç®—ã€‚")

# -----------------------------------------------------------------------------
# Tab 4: å…³äºæœ¬é¡¹ç›®
# -----------------------------------------------------------------------------

st.markdown("---")
st.markdown("### ğŸ‘¨â€ğŸ’» å…³äºæœ¬é¡¹ç›®")
st.info(
    "æœ¬é¡¹ç›®æ—¨åœ¨é€šè¿‡å¯è§†åŒ–æ‰‹æ®µï¼Œ"
    "ç›´è§‚å¯¹æ¯” **Transformer** ä¸ **Mamba (SSM)** "
    "çš„åº•å±‚æœºåˆ¶å·®å¼‚ã€‚"
)
st.caption("Â© 2025 Just For Dream Lab")
