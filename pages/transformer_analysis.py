"""
Transformeråˆ†æé¡µé¢ï¼šæä¾›Transformeræ¨¡å‹ç»“æ„åˆ†æã€å‚æ•°çƒ­ç‚¹åˆ†æç­‰å·¥å…·
"""
import streamlit as st
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

from utils.model_profiler import TransformerProfiler, create_sample_transformer
import plotly.graph_objects as go
import plotly.express as px
import pandas as pd
import numpy as np

st.set_page_config(page_title="Transformeræ¶æ„åˆ†æ", page_icon="ğŸ¤–", layout="wide")

st.title("ğŸ¤– Transformer æ¶æ„åˆ†æå·¥å…·")
st.markdown("### æ·±åº¦å‰–æTransformeræ¨¡å‹ç»“æ„ã€å‚æ•°åˆ†å¸ƒå’Œæ€§èƒ½ç“¶é¢ˆ")

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("âš™ï¸ æ¨¡å‹é…ç½®")
    
    d_model = st.slider("åµŒå…¥ç»´åº¦ (d_model)", 128, 2048, 512, step=128)
    n_heads = st.select_slider("æ³¨æ„åŠ›å¤´æ•°", [4, 8, 12, 16, 32], value=8)
    n_layers = st.slider("å±‚æ•°", 1, 24, 6)
    vocab_size = st.select_slider("è¯è¡¨å¤§å°", [10000, 30000, 50000, 100000], value=50000)
    
    st.divider()
    
    st.header("ğŸ’¾ æ¨ç†é…ç½®")
    batch_size = st.slider("Batch Size", 1, 64, 8)
    seq_len = st.slider("åºåˆ—é•¿åº¦", 32, 2048, 128, step=32)
    
    st.divider()
    
    precision = st.radio("ç²¾åº¦", ["FP32", "FP16", "BF16"], index=2)
    dtype_map = {"FP32": 4, "FP16": 2, "BF16": 2}
    bytes_per_element = dtype_map[precision]

# åˆ›å»ºæ¨¡å‹å’Œåˆ†æå™¨
model = create_sample_transformer(d_model, n_heads, n_layers, vocab_size)
profiler = TransformerProfiler(model, (batch_size, seq_len, d_model))

# ä¸»ç•Œé¢æ ‡ç­¾é¡µ
tab1, tab2, tab3, tab4 = st.tabs([
    "ğŸ“Š å‚æ•°åˆ†æ",
    "âš¡ è®¡ç®—å¤æ‚åº¦",
    "ğŸ’¾ æ˜¾å­˜åˆ†æ",
    "ğŸ”¥ æ€§èƒ½çƒ­ç‚¹"
])

# =================== TAB 1: å‚æ•°åˆ†æ ===================
with tab1:
    st.header("ğŸ“Š æ¨¡å‹å‚æ•°åˆ†å¸ƒåˆ†æ")
    
    # ç»Ÿè®¡å‚æ•°
    param_counts = profiler.count_parameters()
    total_params = param_counts['total']
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("æ€»å‚æ•°é‡", f"{total_params:,}", help="æ¨¡å‹æ‰€æœ‰å¯è®­ç»ƒå‚æ•°")
    with col2:
        st.metric("å‚æ•°é‡ (M)", f"{total_params/1e6:.2f}M")
    with col3:
        st.metric("å‚æ•°é‡ (B)", f"{total_params/1e9:.4f}B")
    
    st.divider()
    
    # å±‚çº§å‚æ•°åˆ†å¸ƒ
    st.subheader("ğŸ—ï¸ å„å±‚å‚æ•°åˆ†å¸ƒ")
    
    profiles = profiler.profile_layers(batch_size, seq_len, d_model, n_heads, n_layers)
    
    # åˆ›å»ºæ•°æ®æ¡†
    layer_data = []
    for p in profiles:
        layer_data.append({
            "å±‚åç§°": p.name,
            "å‚æ•°é‡": p.params,
            "å‚æ•°å æ¯” (%)": p.param_ratio,
            "æ˜¾å­˜ (MB)": p.memory_mb
        })
    
    df = pd.DataFrame(layer_data)
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        # é¥¼å›¾ï¼šå‚æ•°åˆ†å¸ƒ
        fig = px.pie(df, values='å‚æ•°é‡', names='å±‚åç§°', 
                     title='å‚æ•°åˆ†å¸ƒé¥¼å›¾',
                     hover_data=['å‚æ•°å æ¯” (%)'])
        fig.update_traces(textposition='inside', textinfo='percent+label')
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # è¡¨æ ¼æ˜¾ç¤º
        st.dataframe(
            df.style.format({
                'å‚æ•°é‡': '{:,}',
                'å‚æ•°å æ¯” (%)': '{:.2f}',
                'æ˜¾å­˜ (MB)': '{:.2f}'
            }).background_gradient(subset=['å‚æ•°å æ¯” (%)'], cmap='YlOrRd'),
            height=400
        )
    
    st.divider()
    
    # ç»„ä»¶çº§å‚æ•°åˆ†æ
    st.subheader("ğŸ” ç»„ä»¶çº§å‚æ•°åˆ†æ")
    
    # è®¡ç®—å„ç»„ä»¶å‚æ•°é‡
    embedding_params = vocab_size * d_model
    attention_params_per_layer = 4 * d_model * d_model
    ffn_params_per_layer = 2 * d_model * 4 * d_model
    output_params = vocab_size * d_model
    
    component_data = {
        "ç»„ä»¶": ["Embedding", "Self-Attention (æ‰€æœ‰å±‚)", "FFN (æ‰€æœ‰å±‚)", "Output Layer"],
        "å‚æ•°é‡": [
            embedding_params,
            attention_params_per_layer * n_layers,
            ffn_params_per_layer * n_layers,
            output_params
        ]
    }
    
    df_comp = pd.DataFrame(component_data)
    df_comp['å‚æ•°å æ¯” (%)'] = df_comp['å‚æ•°é‡'] / df_comp['å‚æ•°é‡'].sum() * 100
    
    fig = px.bar(df_comp, x='ç»„ä»¶', y='å‚æ•°é‡', 
                 color='å‚æ•°å æ¯” (%)',
                 text='å‚æ•°é‡',
                 title='ç»„ä»¶å‚æ•°é‡å¯¹æ¯”')
    fig.update_traces(texttemplate='%{text:,.0f}', textposition='outside')
    st.plotly_chart(fig, use_container_width=True)
    
    st.markdown(f"""
    **å…³é”®è§‚å¯Ÿ**ï¼š
    - **Embedding + Output**: {(embedding_params + output_params)/1e6:.2f}M å‚æ•° 
      ({(embedding_params + output_params)/total_params*100:.1f}%)
    - **Attention**: {attention_params_per_layer * n_layers/1e6:.2f}M å‚æ•°
      ({attention_params_per_layer * n_layers/total_params*100:.1f}%)
    - **FFN**: {ffn_params_per_layer * n_layers/1e6:.2f}M å‚æ•°
      ({ffn_params_per_layer * n_layers/total_params*100:.1f}%)
    
    ğŸ’¡ **ä¼˜åŒ–å»ºè®®**ï¼š
    - è¯è¡¨ç›¸å…³å±‚å æ®äº†å¤§é‡å‚æ•°ï¼Œè€ƒè™‘ä½¿ç”¨ **è¯è¡¨å‹ç¼©** æˆ– **æƒé‡å…±äº«**
    - FFN å‚æ•°é‡çº¦ä¸º Attention çš„ 2 å€ï¼Œæ˜¯ä¼˜åŒ–é‡ç‚¹
    """)

# =================== TAB 2: è®¡ç®—å¤æ‚åº¦ ===================
with tab2:
    st.header("âš¡ è®¡ç®—å¤æ‚åº¦åˆ†æ")
    
    # ä¼°ç®— FLOPs
    flops_data = profiler.estimate_flops(batch_size, seq_len, d_model, n_heads, n_layers, vocab_size)
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("å•å±‚ FLOPs", f"{flops_data['total_per_layer']/1e9:.2f} GFLOPs")
    with col2:
        st.metric("æ€» FLOPs", f"{flops_data['total_model']/1e9:.2f} GFLOPs")
    with col3:
        throughput = flops_data['total_model'] / 1e12  # TFLOPs
        st.metric("ååé‡éœ€æ±‚", f"{throughput:.3f} TFLOPs")
    
    st.divider()
    
    # FLOPs åˆ†è§£
    st.subheader("ğŸ”¬ FLOPs åˆ†è§£åˆ†æ")
    
    flops_breakdown = {
        "æ“ä½œ": [
            "QKV æŠ•å½±",
            "Attention è®¡ç®—",
            "FFN",
            "å…¶ä»–"
        ],
        "FLOPs": [
            flops_data['qkv_projection'],
            flops_data['attention_matrix'],
            flops_data['ffn_total'],
            flops_data['total_per_layer'] - flops_data['qkv_projection'] - 
            flops_data['attention_matrix'] - flops_data['ffn_total']
        ]
    }
    
    df_flops = pd.DataFrame(flops_breakdown)
    df_flops['å æ¯” (%)'] = df_flops['FLOPs'] / df_flops['FLOPs'].sum() * 100
    
    col1, col2 = st.columns(2)
    
    with col1:
        fig = px.pie(df_flops, values='FLOPs', names='æ“ä½œ',
                     title='å•å±‚ FLOPs åˆ†å¸ƒ')
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        fig = px.bar(df_flops, x='æ“ä½œ', y='FLOPs',
                     color='å æ¯” (%)',
                     text='FLOPs',
                     title='FLOPs å¯¹æ¯”')
        fig.update_traces(texttemplate='%{text:.2e}')
        st.plotly_chart(fig, use_container_width=True)
    
    st.divider()
    
    # åºåˆ—é•¿åº¦å½±å“åˆ†æ
    st.subheader("ğŸ“ˆ åºåˆ—é•¿åº¦å¯¹å¤æ‚åº¦çš„å½±å“")
    
    seq_lengths = [64, 128, 256, 512, 1024, 2048]
    complexity_data = profiler.get_attention_complexity_comparison(seq_lengths, d_model)
    
    df_complexity = pd.DataFrame({
        'åºåˆ—é•¿åº¦': seq_lengths,
        'Transformer (O(LÂ²))': complexity_data['transformer_flops'],
        'Linear Attention (O(LdÂ²))': complexity_data['linear_attention_flops'],
        'Mamba (O(LdN))': complexity_data['mamba_flops']
    })
    
    fig = go.Figure()
    fig.add_trace(go.Scatter(x=seq_lengths, y=df_complexity['Transformer (O(LÂ²))'], 
                            mode='lines+markers', name='Transformer', line=dict(width=3)))
    fig.add_trace(go.Scatter(x=seq_lengths, y=df_complexity['Linear Attention (O(LdÂ²))'], 
                            mode='lines+markers', name='Linear Attention'))
    fig.add_trace(go.Scatter(x=seq_lengths, y=df_complexity['Mamba (O(LdN))'], 
                            mode='lines+markers', name='Mamba'))
    
    fig.update_layout(
        title='ä¸åŒæ¶æ„çš„è®¡ç®—å¤æ‚åº¦å¯¹æ¯”',
        xaxis_title='åºåˆ—é•¿åº¦',
        yaxis_title='FLOPs',
        yaxis_type='log',
        height=500
    )
    st.plotly_chart(fig, use_container_width=True)
    
    st.markdown("""
    **å…³é”®ç»“è®º**ï¼š
    - ğŸ”´ **Transformer**: å¤æ‚åº¦éšåºåˆ—é•¿åº¦**å¹³æ–¹**å¢é•¿ï¼Œé•¿åºåˆ—åœºæ™¯ä»£ä»·é«˜æ˜‚
    - ğŸŸ¡ **Linear Attention**: çº¿æ€§å¤æ‚åº¦ï¼Œä½†éœ€è¦è¿‘ä¼¼
    - ğŸŸ¢ **Mamba**: çº¿æ€§å¤æ‚åº¦ä¸”æ€§èƒ½æ¥è¿‘ï¼Œé•¿åºåˆ—ä¼˜åŠ¿æ˜æ˜¾
    
    **ä¸´ç•Œç‚¹åˆ†æ**ï¼š
    """)
    
    # æ‰¾åˆ° Transformer vs Mamba çš„äº¤å‰ç‚¹
    for i, L in enumerate(seq_lengths):
        if complexity_data['transformer_flops'][i] > complexity_data['mamba_flops'][i] * 10:
            st.info(f"ğŸ’¡ å½“åºåˆ—é•¿åº¦è¶…è¿‡ **{L}** æ—¶ï¼ŒMamba çš„è®¡ç®—ä¼˜åŠ¿è¾¾åˆ° **10å€** ä»¥ä¸Š")
            break

st.markdown("---")
st.caption("ğŸ”¬ Transformer Explorer - Model Analysis Tool | Â© 2025")

# =================== TAB 3: æ˜¾å­˜åˆ†æ ===================
with tab3:
    st.header("ğŸ’¾ æ˜¾å­˜å ç”¨åˆ†æ")
    
    # ä¼°ç®—æ˜¾å­˜
    import torch
    memory_data = profiler.estimate_memory(batch_size, seq_len, d_model, n_layers, 
                                          dtype=torch.float32 if precision == "FP32" else torch.float16)
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("å‚æ•°æ˜¾å­˜", f"{memory_data['parameters_mb']:.0f} MB")
    with col2:
        st.metric("æ¿€æ´»æ˜¾å­˜", f"{memory_data['activation_total_mb']:.0f} MB")
    with col3:
        st.metric("è®­ç»ƒæ€»æ˜¾å­˜", f"{memory_data['total_training_mb']:.0f} MB", 
                 help="åŒ…å«å‚æ•°ã€æ¿€æ´»ã€æ¢¯åº¦ã€ä¼˜åŒ–å™¨çŠ¶æ€")
    with col4:
        st.metric("æ¨ç†æ˜¾å­˜", f"{memory_data['total_inference_mb']:.0f} MB")
    
    st.divider()
    
    # æ˜¾å­˜åˆ†è§£
    st.subheader("ğŸ“Š è®­ç»ƒæ—¶æ˜¾å­˜åˆ†è§£")
    
    memory_breakdown = {
        "ç±»å‹": ["æ¨¡å‹å‚æ•°", "æ¿€æ´»å€¼", "æ¢¯åº¦", "ä¼˜åŒ–å™¨çŠ¶æ€ (AdamW)"],
        "æ˜¾å­˜ (MB)": [
            memory_data['parameters_mb'],
            memory_data['activation_total_mb'],
            memory_data['gradients_mb'],
            memory_data['optimizer_mb']
        ]
    }
    
    df_mem = pd.DataFrame(memory_breakdown)
    df_mem['å æ¯” (%)'] = df_mem['æ˜¾å­˜ (MB)'] / df_mem['æ˜¾å­˜ (MB)'].sum() * 100
    
    col1, col2 = st.columns(2)
    
    with col1:
        fig = px.pie(df_mem, values='æ˜¾å­˜ (MB)', names='ç±»å‹',
                     title=f'è®­ç»ƒæ˜¾å­˜åˆ†å¸ƒ ({precision})')
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.dataframe(
            df_mem.style.format({
                'æ˜¾å­˜ (MB)': '{:.1f}',
                'å æ¯” (%)': '{:.1f}'
            }).background_gradient(subset=['å æ¯” (%)'], cmap='Reds'),
            height=200
        )
        
        st.markdown(f'''
        **æ˜¾å­˜å ç”¨åˆ†æ**ï¼š
        - ğŸ’¾ ä¼˜åŒ–å™¨çŠ¶æ€å æ®äº† **{memory_data['optimizer_mb']/memory_data['total_training_mb']*100:.1f}%** çš„æ˜¾å­˜
        - ğŸ”¥ æ¿€æ´»å€¼å  **{memory_data['activation_total_mb']/memory_data['total_training_mb']*100:.1f}%**
        - ğŸ“‰ ä½¿ç”¨ **Gradient Checkpointing** å¯å‡å°‘æ¿€æ´»æ˜¾å­˜è‡³åŸæ¥çš„ 1/âˆšL
        ''')
    
    st.divider()
    
    # ç²¾åº¦å¯¹æ¯”
    st.subheader("ğŸ¯ ç²¾åº¦å¯¹æ˜¾å­˜çš„å½±å“")
    
    precisions = ["FP32", "FP16", "BF16"]
    precision_memory = []
    
    for prec in precisions:
        dtype = torch.float32 if prec == "FP32" else torch.float16
        mem = profiler.estimate_memory(batch_size, seq_len, d_model, n_layers, dtype)
        precision_memory.append({
            "ç²¾åº¦": prec,
            "è®­ç»ƒæ˜¾å­˜ (GB)": mem['total_training_mb'] / 1024,
            "æ¨ç†æ˜¾å­˜ (GB)": mem['total_inference_mb'] / 1024,
            "èŠ‚çœæ¯”ä¾‹": "0%" if prec == "FP32" else "50%"
        })
    
    df_prec = pd.DataFrame(precision_memory)
    
    fig = go.Figure()
    fig.add_trace(go.Bar(name='è®­ç»ƒ', x=df_prec['ç²¾åº¦'], y=df_prec['è®­ç»ƒæ˜¾å­˜ (GB)']))
    fig.add_trace(go.Bar(name='æ¨ç†', x=df_prec['ç²¾åº¦'], y=df_prec['æ¨ç†æ˜¾å­˜ (GB)']))
    fig.update_layout(
        title='ä¸åŒç²¾åº¦ä¸‹çš„æ˜¾å­˜å ç”¨',
        xaxis_title='ç²¾åº¦',
        yaxis_title='æ˜¾å­˜ (GB)',
        barmode='group',
        height=400
    )
    st.plotly_chart(fig, use_container_width=True)
    
    st.info(f'''
    ğŸ’¡ **ä¼˜åŒ–å»ºè®®**ï¼š
    - ä½¿ç”¨ **BF16** æ··åˆç²¾åº¦è®­ç»ƒå¯èŠ‚çœ **50%** æ˜¾å­˜
    - å½“å‰é…ç½®ä¸‹ï¼Œæ¨èçš„æœ€å°æ˜¾å¡æ˜¾å­˜ï¼š
      - FP32 è®­ç»ƒ: **{df_prec.iloc[0]['è®­ç»ƒæ˜¾å­˜ (GB)']*1.2:.1f} GB** (å«ä½™é‡)
      - BF16 è®­ç»ƒ: **{df_prec.iloc[2]['è®­ç»ƒæ˜¾å­˜ (GB)']*1.2:.1f} GB**
      - BF16 æ¨ç†: **{df_prec.iloc[2]['æ¨ç†æ˜¾å­˜ (GB)']*1.2:.1f} GB**
    ''')
    
    st.divider()
    
    # Batch Size å½±å“åˆ†æ
    st.subheader("ğŸ“¦ Batch Size å¯¹æ˜¾å­˜çš„å½±å“")
    
    batch_sizes = [1, 2, 4, 8, 16, 32, 64]
    batch_memory = []
    
    for bs in batch_sizes:
        mem = profiler.estimate_memory(bs, seq_len, d_model, n_layers, torch.float16)
        batch_memory.append(mem['total_training_mb'] / 1024)  # Convert to GB
    
    fig = go.Figure()
    fig.add_trace(go.Scatter(x=batch_sizes, y=batch_memory, mode='lines+markers',
                            line=dict(width=3, color='blue')))
    fig.update_layout(
        title='Batch Size vs æ˜¾å­˜å ç”¨',
        xaxis_title='Batch Size',
        yaxis_title='æ˜¾å­˜ (GB)',
        height=400
    )
    
    # æ·»åŠ æ˜¾å¡æ˜¾å­˜çº¿
    common_gpus = {
        'RTX 3090': 24,
        'A100 (40GB)': 40,
        'A100 (80GB)': 80,
        'H100': 80
    }
    
    for gpu_name, gpu_mem in common_gpus.items():
        fig.add_hline(y=gpu_mem, line_dash="dash", 
                     annotation_text=gpu_name, 
                     annotation_position="right")
    
    st.plotly_chart(fig, use_container_width=True)
    
    # æ‰¾åˆ°æ¯ä¸ª GPU çš„æœ€å¤§ batch size
    st.markdown("**å„æ˜¾å¡æ¨èçš„æœ€å¤§ Batch Size**ï¼š")
    for gpu_name, gpu_mem in common_gpus.items():
        max_bs = 1
        for i, bs in enumerate(batch_sizes):
            if batch_memory[i] <= gpu_mem * 0.9:  # ç•™ 10% ä½™é‡
                max_bs = bs
        st.write(f"- **{gpu_name}**: Batch Size â‰¤ **{max_bs}**")

# =================== TAB 4: æ€§èƒ½çƒ­ç‚¹ ===================
with tab4:
    st.header("ğŸ”¥ æ€§èƒ½çƒ­ç‚¹åˆ†æ")
    
    st.info("ğŸ’¡ æœ¬é¡µé¢å¸®åŠ©ä½ è¯†åˆ«è®­ç»ƒè¿‡ç¨‹ä¸­çš„ç“¶é¢ˆï¼Œæ‰¾åˆ°æœ€å€¼å¾—ä¼˜åŒ–çš„éƒ¨åˆ†")
    
    # è®­ç»ƒæ­¥æ—¶é—´åˆ†è§£
    st.subheader("â±ï¸ å•æ­¥è®­ç»ƒæ—¶é—´åˆ†è§£")
    
    timing = profiler.simulate_training_step(batch_size, seq_len, d_model, n_layers)
    
    timing_data = {
        "é˜¶æ®µ": ["Forward", "Attention", "FFN", "Backward", "Optimizer"],
        "æ—¶é—´ (ms)": [
            timing['forward_ms'],
            timing['attention_ms'],
            timing['ffn_ms'],
            timing['backward_ms'],
            timing['optimizer_step_ms']
        ]
    }
    
    df_timing = pd.DataFrame(timing_data)
    df_timing['å æ¯” (%)'] = df_timing['æ—¶é—´ (ms)'] / timing['total_ms'] * 100
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        fig = px.bar(df_timing, x='é˜¶æ®µ', y='æ—¶é—´ (ms)',
                     color='å æ¯” (%)',
                     title='å•æ­¥è®­ç»ƒæ—¶é—´åˆ†å¸ƒ',
                     text='æ—¶é—´ (ms)')
        fig.update_traces(texttemplate='%{text:.2f}ms', textposition='outside')
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.metric("æ€»æ—¶é—´", f"{timing['total_ms']:.2f} ms")
        st.metric("ååé‡", f"{1000/timing['total_ms']:.1f} steps/s")
        st.metric("æ ·æœ¬ååé‡", f"{batch_size*1000/timing['total_ms']:.0f} samples/s")
        
        st.markdown(f'''
        **å…³é”®è§‚å¯Ÿ**ï¼š
        - Backward æ˜¯ Forward çš„ **{timing['backward_ms']/timing['forward_ms']:.1f}x**
        - Attention å  Forward çš„ **{timing['attention_ms']/timing['forward_ms']*100:.0f}%**
        ''')
    
    st.divider()
    
    # å‚æ•°æ›´æ–°çƒ­ç‚¹ï¼ˆæ¨¡æ‹Ÿï¼‰
    st.subheader("ğŸ¯ å‚æ•°æ›´æ–°çƒ­ç‚¹è¯†åˆ«")
    
    st.markdown('''
    åœ¨å®é™…è®­ç»ƒä¸­ï¼Œä¸åŒå±‚çš„å‚æ•°æ›´æ–°å¹…åº¦å·®å¼‚å·¨å¤§ã€‚è¯†åˆ«è¿™äº›"çƒ­ç‚¹"å¯ä»¥å¸®åŠ©ï¼š
    - ğŸ¯ **é’ˆå¯¹æ€§è°ƒæ•´å­¦ä¹ ç‡**ï¼ˆLayer-wise LRï¼‰
    - ğŸ” **å‘ç°è®­ç»ƒé—®é¢˜**ï¼ˆæŸäº›å±‚ä¸æ›´æ–°ï¼‰
    - âš¡ **ä¼˜åŒ–è®­ç»ƒç­–ç•¥**ï¼ˆå†»ç»“ä¸é‡è¦çš„å±‚ï¼‰
    ''')
    
    # æ¨¡æ‹Ÿæ¢¯åº¦çƒ­ç‚¹æ•°æ®
    np.random.seed(42)
    hotspot_data = []
    
    for i in range(n_layers):
        # æ¨¡æ‹Ÿï¼šæµ…å±‚æ›´æ–°æ…¢ï¼Œæ·±å±‚æ›´æ–°å¿«
        update_ratio = 0.001 * (1 + i / n_layers) * np.random.uniform(0.5, 1.5)
        
        hotspot_data.append({
            "å±‚": f"Layer {i+1} Attention",
            "æ¢¯åº¦èŒƒæ•°": np.random.uniform(0.1, 2.0),
            "å‚æ•°èŒƒæ•°": np.random.uniform(5.0, 15.0),
            "æ›´æ–°æ¯”ä¾‹": update_ratio,
            "æ˜¯å¦çƒ­ç‚¹": "ğŸ”¥" if update_ratio > 0.0015 else "â„ï¸"
        })
        
        update_ratio_ffn = 0.0012 * (1 + i / n_layers) * np.random.uniform(0.5, 1.5)
        hotspot_data.append({
            "å±‚": f"Layer {i+1} FFN",
            "æ¢¯åº¦èŒƒæ•°": np.random.uniform(0.1, 2.0),
            "å‚æ•°èŒƒæ•°": np.random.uniform(10.0, 25.0),
            "æ›´æ–°æ¯”ä¾‹": update_ratio_ffn,
            "æ˜¯å¦çƒ­ç‚¹": "ğŸ”¥" if update_ratio_ffn > 0.0015 else "â„ï¸"
        })
    
    df_hotspot = pd.DataFrame(hotspot_data)
    
    # çƒ­ç‚¹å¯è§†åŒ–
    fig = px.bar(df_hotspot, x='å±‚', y='æ›´æ–°æ¯”ä¾‹',
                 color='æ˜¯å¦çƒ­ç‚¹',
                 title='å„å±‚å‚æ•°æ›´æ–°çƒ­ç‚¹åˆ†å¸ƒ',
                 color_discrete_map={"ğŸ”¥": "#e74c3c", "â„ï¸": "#3498db"})
    fig.add_hline(y=0.0015, line_dash="dash", 
                 annotation_text="çƒ­ç‚¹é˜ˆå€¼", 
                 line_color="red")
    fig.update_layout(height=400, xaxis_tickangle=-45)
    st.plotly_chart(fig, use_container_width=True)
    
    # è¡¨æ ¼æ˜¾ç¤ºï¼ˆåªæ˜¾ç¤ºå‰10è¡Œï¼‰
    st.dataframe(
        df_hotspot.head(10).style.format({
            'æ¢¯åº¦èŒƒæ•°': '{:.4f}',
            'å‚æ•°èŒƒæ•°': '{:.2f}',
            'æ›´æ–°æ¯”ä¾‹': '{:.6f}'
        }).background_gradient(subset=['æ›´æ–°æ¯”ä¾‹'], cmap='YlOrRd'),
        height=300
    )
    
    st.divider()
    
    # ä¼˜åŒ–å»ºè®®
    st.subheader("ğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown('''
        ### ğŸš€ è®¡ç®—ä¼˜åŒ–
        
        1. **Flash Attention**
           - å‡å°‘ Attention æ˜¾å­˜è®¿é—®
           - åŠ é€Ÿ 2-4x
           - é€‚ç”¨äºé•¿åºåˆ—
        
        2. **Gradient Checkpointing**
           - ä»¥è®¡ç®—æ¢æ˜¾å­˜
           - æ¿€æ´»æ˜¾å­˜å‡å°‘è‡³ O(âˆšL)
           - è®­ç»ƒæ—¶é—´å¢åŠ  20-30%
        
        3. **Mixed Precision (BF16)**
           - é€Ÿåº¦æå‡ 2-3x
           - æ˜¾å­˜èŠ‚çœ 50%
           - ç°ä»£ GPU å¿…å¤‡
        ''')
    
    with col2:
        st.markdown('''
        ### ğŸ¯ æ¶æ„ä¼˜åŒ–
        
        1. **Multi-Query Attention**
           - å‡å°‘ KV Cache
           - æ¨ç†åŠ é€Ÿ 1.5-2x
           - PaLM/Falcon ä½¿ç”¨
        
        2. **SwiGLU FFN**
           - æ›¿ä»£ ReLU/GELU
           - æ€§èƒ½æå‡ 5-10%
           - LLaMA ç³»åˆ—é‡‡ç”¨
        
        3. **RoPE ä½ç½®ç¼–ç **
           - å¤–æ¨èƒ½åŠ›å¼º
           - æ— é¢å¤–å‚æ•°
           - ç›¸å¯¹ä½ç½®ç¼–ç 
        ''')
    
    # å®é™…æ”¶ç›Šè¯„ä¼°
    st.markdown("### ğŸ“Š ä¼˜åŒ–æ”¶ç›Šè¯„ä¼°")
    
    optimizations = {
        "ä¼˜åŒ–æ–¹æ³•": [
            "Baseline",
            "+ Flash Attention",
            "+ BF16",
            "+ Gradient Checkpointing",
            "+ All"
        ],
        "è®­ç»ƒæ—¶é—´ (ç›¸å¯¹)": [1.0, 0.7, 0.4, 0.5, 0.3],
        "æ˜¾å­˜å ç”¨ (ç›¸å¯¹)": [1.0, 0.9, 0.5, 0.3, 0.15]
    }
    
    df_opt = pd.DataFrame(optimizations)
    
    fig = go.Figure()
    fig.add_trace(go.Bar(name='è®­ç»ƒæ—¶é—´', x=df_opt['ä¼˜åŒ–æ–¹æ³•'], 
                        y=df_opt['è®­ç»ƒæ—¶é—´ (ç›¸å¯¹)'], 
                        text=df_opt['è®­ç»ƒæ—¶é—´ (ç›¸å¯¹)'],
                        texttemplate='%{text:.1f}x'))
    fig.add_trace(go.Bar(name='æ˜¾å­˜å ç”¨', x=df_opt['ä¼˜åŒ–æ–¹æ³•'], 
                        y=df_opt['æ˜¾å­˜å ç”¨ (ç›¸å¯¹)'],
                        text=df_opt['æ˜¾å­˜å ç”¨ (ç›¸å¯¹)'],
                        texttemplate='%{text:.2f}x'))
    
    fig.update_layout(
        title='ä¼˜åŒ–æ–¹æ³•æ•ˆæœå¯¹æ¯”ï¼ˆç›¸å¯¹äº Baselineï¼‰',
        xaxis_title='ä¼˜åŒ–ç»„åˆ',
        yaxis_title='ç›¸å¯¹å€¼ï¼ˆè¶Šå°è¶Šå¥½ï¼‰',
        barmode='group',
        height=400
    )
    st.plotly_chart(fig, use_container_width=True)
    
    st.success('''
    ğŸ‰ **ç»¼åˆä¼˜åŒ–æ•ˆæœ**ï¼š
    - è®­ç»ƒé€Ÿåº¦æå‡ï¼š**3.3x**
    - æ˜¾å­˜èŠ‚çœï¼š**85%**
    - å¯è®­ç»ƒçš„æœ€å¤§æ¨¡å‹è§„æ¨¡æå‡ï¼š**6-7x**
    ''')

